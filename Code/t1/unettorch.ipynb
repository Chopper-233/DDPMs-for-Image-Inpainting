{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net\n",
    "\n",
    " - Originally introduyced as an image segmentation tool for detecting tumours\n",
    " - U-Net is computationally less expensive and minimises information loss, compared to predecessors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Operations\n",
    "\n",
    "### Convolutions\n",
    "\n",
    " - Retains the influence of all input pixels but keeps them only loosely connected to reduce computation cost\n",
    " - Passes a filter matrix K over the image\n",
    " - Consider an input matrix with dimensions (Height x Width x Depth/Channels) A x B x C\n",
    " - Consider a filter matrix with dimensions (Height, Width, Depth (same as image), Number of filters) f x f x C x G\n",
    " - We have padding p and stride s\n",
    " - The output matrix will have dimensions H x W x G\n",
    "   - H = $\\lfloor\\frac{A+2p-f}{s}+1\\rfloor$\n",
    "\n",
    "   - G = $\\lfloor\\frac{B+2p-f}{s}+1\\rfloor$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transposed Convolutions (up-conv)\n",
    "\n",
    " - Transposed convolutions upscale images (compared to standard convolutions which reduce resolution)\n",
    " - This is achieved by using a filter bigger than the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling (max pool)\n",
    "\n",
    " - Pooling is used for the same purpose as convolution (reducing parameters)\n",
    " - Also provides regularisation\n",
    " - Average or max\n",
    " - We create subsets of the input based on filter size f and stride s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip Connections (copy and crop)\n",
    "\n",
    " - These copy the image matrix from earlier layers and uses it as a part of the later layers\n",
    " - Enables the preservation of image from a richer matrix and prevents information loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv(3x3) -> batch norm -> relu -> conv(3x3) -> batch norm -> relu\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        # x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        # x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv block -> maxpool(2,2)\n",
    "class EncBlock(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv = ConvBlock(in_c, out_c)\n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        p = self.pool(x)\n",
    "        return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convtransp -> conv\n",
    "class DecBlock(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv = ConvBlock(out_c + out_c, out_c)\n",
    "\n",
    "    def forward(self, inputs, skip):\n",
    "        x = self.up(inputs)\n",
    "        x = torch.cat([x, skip], axis=1)\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in -> encblock -> encblock -> encblock -> encblock -> convblock <- decblock <- decblock <- decblock <- decblock <- out\n",
    "class UNET(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.e1 = EncBlock(3, 64)\n",
    "        self.e2 = EncBlock(64, 128)\n",
    "        self.e3 = EncBlock(128, 256)\n",
    "        self.e4 = EncBlock(256, 512)\n",
    "        # Bottleneck\n",
    "        self.b = ConvBlock(512, 1024)\n",
    "        # Decoder\n",
    "        self.d1 = DecBlock(1024, 512)\n",
    "        self.d2 = DecBlock(512, 256)\n",
    "        self.d3 = DecBlock(256, 128)\n",
    "        self.d4 = DecBlock(128, 64)\n",
    "        # Classifier\n",
    "        self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Encoder\n",
    "        s1, p1 = self.e1(inputs)\n",
    "        s2, p2 = self.e2(p1)\n",
    "        s3, p3 = self.e3(p2)\n",
    "        s4, p4 = self.e4(p3)\n",
    "        # Bottlenek\n",
    "        b = self.b(p4)\n",
    "        # Decoder\n",
    "        d1 = self.d1(b, s4)\n",
    "        d2 = self.d2(d1, s3)\n",
    "        d3 = self.d3(d2, s2)\n",
    "        d4 = self.d4(d3, s1)\n",
    "        # Classifier\n",
    "        outputs = self.outputs(d4)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 512, 512])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 512, 512]           1,792\n",
      "              ReLU-2         [-1, 64, 512, 512]               0\n",
      "            Conv2d-3         [-1, 64, 512, 512]          36,928\n",
      "              ReLU-4         [-1, 64, 512, 512]               0\n",
      "         ConvBlock-5         [-1, 64, 512, 512]               0\n",
      "         MaxPool2d-6         [-1, 64, 256, 256]               0\n",
      "          EncBlock-7  [[-1, 64, 512, 512], [-1, 64, 256, 256]]               0\n",
      "            Conv2d-8        [-1, 128, 256, 256]          73,856\n",
      "              ReLU-9        [-1, 128, 256, 256]               0\n",
      "           Conv2d-10        [-1, 128, 256, 256]         147,584\n",
      "             ReLU-11        [-1, 128, 256, 256]               0\n",
      "        ConvBlock-12        [-1, 128, 256, 256]               0\n",
      "        MaxPool2d-13        [-1, 128, 128, 128]               0\n",
      "         EncBlock-14  [[-1, 128, 256, 256], [-1, 128, 128, 128]]               0\n",
      "           Conv2d-15        [-1, 256, 128, 128]         295,168\n",
      "             ReLU-16        [-1, 256, 128, 128]               0\n",
      "           Conv2d-17        [-1, 256, 128, 128]         590,080\n",
      "             ReLU-18        [-1, 256, 128, 128]               0\n",
      "        ConvBlock-19        [-1, 256, 128, 128]               0\n",
      "        MaxPool2d-20          [-1, 256, 64, 64]               0\n",
      "         EncBlock-21  [[-1, 256, 128, 128], [-1, 256, 64, 64]]               0\n",
      "           Conv2d-22          [-1, 512, 64, 64]       1,180,160\n",
      "             ReLU-23          [-1, 512, 64, 64]               0\n",
      "           Conv2d-24          [-1, 512, 64, 64]       2,359,808\n",
      "             ReLU-25          [-1, 512, 64, 64]               0\n",
      "        ConvBlock-26          [-1, 512, 64, 64]               0\n",
      "        MaxPool2d-27          [-1, 512, 32, 32]               0\n",
      "         EncBlock-28  [[-1, 512, 64, 64], [-1, 512, 32, 32]]               0\n",
      "           Conv2d-29         [-1, 1024, 32, 32]       4,719,616\n",
      "             ReLU-30         [-1, 1024, 32, 32]               0\n",
      "           Conv2d-31         [-1, 1024, 32, 32]       9,438,208\n",
      "             ReLU-32         [-1, 1024, 32, 32]               0\n",
      "        ConvBlock-33         [-1, 1024, 32, 32]               0\n",
      "  ConvTranspose2d-34          [-1, 512, 64, 64]       2,097,664\n",
      "           Conv2d-35          [-1, 512, 64, 64]       4,719,104\n",
      "             ReLU-36          [-1, 512, 64, 64]               0\n",
      "           Conv2d-37          [-1, 512, 64, 64]       2,359,808\n",
      "             ReLU-38          [-1, 512, 64, 64]               0\n",
      "        ConvBlock-39          [-1, 512, 64, 64]               0\n",
      "         DecBlock-40          [-1, 512, 64, 64]               0\n",
      "  ConvTranspose2d-41        [-1, 256, 128, 128]         524,544\n",
      "           Conv2d-42        [-1, 256, 128, 128]       1,179,904\n",
      "             ReLU-43        [-1, 256, 128, 128]               0\n",
      "           Conv2d-44        [-1, 256, 128, 128]         590,080\n",
      "             ReLU-45        [-1, 256, 128, 128]               0\n",
      "        ConvBlock-46        [-1, 256, 128, 128]               0\n",
      "         DecBlock-47        [-1, 256, 128, 128]               0\n",
      "  ConvTranspose2d-48        [-1, 128, 256, 256]         131,200\n",
      "           Conv2d-49        [-1, 128, 256, 256]         295,040\n",
      "             ReLU-50        [-1, 128, 256, 256]               0\n",
      "           Conv2d-51        [-1, 128, 256, 256]         147,584\n",
      "             ReLU-52        [-1, 128, 256, 256]               0\n",
      "        ConvBlock-53        [-1, 128, 256, 256]               0\n",
      "         DecBlock-54        [-1, 128, 256, 256]               0\n",
      "  ConvTranspose2d-55         [-1, 64, 512, 512]          32,832\n",
      "           Conv2d-56         [-1, 64, 512, 512]          73,792\n",
      "             ReLU-57         [-1, 64, 512, 512]               0\n",
      "           Conv2d-58         [-1, 64, 512, 512]          36,928\n",
      "             ReLU-59         [-1, 64, 512, 512]               0\n",
      "        ConvBlock-60         [-1, 64, 512, 512]               0\n",
      "         DecBlock-61         [-1, 64, 512, 512]               0\n",
      "           Conv2d-62          [-1, 1, 512, 512]              65\n",
      "================================================================\n",
      "Total params: 31,031,745\n",
      "Trainable params: 31,031,745\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 2982.00\n",
      "Params size (MB): 118.38\n",
      "Estimated Total Size (MB): 3103.38\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    inputs = torch.randn((2, 3, 512, 512))\n",
    "    inputs = inputs.to(dev)\n",
    "    model = UNET()\n",
    "    model = model.to(dev)\n",
    "    y = model(inputs)\n",
    "    print(y.shape)\n",
    "    summary(model, input_size=(3,512,512))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
